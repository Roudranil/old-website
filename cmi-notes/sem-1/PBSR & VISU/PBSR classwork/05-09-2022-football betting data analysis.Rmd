---
title: "Football betting data"
author: "Roudranil Das"
email: "roudranil@cmi.ac.in"
date: "`r Sys.Date()`"
output:
  html_document: default
---
```{r}
library(tidyverse)
```

```{r}
data <- read.csv("E0.csv", header = T)
## FTHG: full time home goals
FTHG <- data[,"FTHG"]
freq_table <- table(FTHG)
freq_table
```

**Using this data we would like to find out the probability that in 22-23, there will be a match where the home team will score 8 or more goals?**

Based on this data, we would say that the prob is 0, but that is not the case. Lets model using a distribution. Candidates:  
1. Poisson  
2. Geometric  
3. Negative binomial  

Let $X: FTHG$. Then say assume $X \sim Poisson(\lambda)$. Then we want to find out
$$P[X \geq 8] = 1 - P[X \leq 7]$$

__Using method of moments__  
We know that $E[X] = \lambda$. Sample mean is a good guess for the population mean. Thus  
```{r}
lambda_hat = mean(FTHG)
lambda_hat
```

This method is not really suitable for many distributions. Hence we would be using the likelihood method.

```{r fig=T}
x1 = FTHG[1]
lambda_star = seq(0.1, 10, length.out = 100)
L = dpois(x1, lambda = lambda_star)
plot(lambda_star, L, pch = 18)
```

For maximum likelihood, $P[D\mid \lambda] = P[X_1 = x_1, X_2 = x_2,\ldots,X_n = x_n \mid \lambda]$. Assuming independence (*SRSWR*). Thus $P[D\mid \lambda] = P[X_1 = x_1\mid \lambda]\cdot P[X_2 = x_2\mid \lambda]\cdots\cdot P[X_n = x_n \mid \lambda]$. However just multiply will be a problem, because as n increases the likelihood will go to 0, but even if it is not 0, it will be rounded to 0 due to computation. To circumvent this, we take the loglikelihood.

```{r fig=T}
prob = dpois(FTHG, lambda = lambda_hat)
plot(FTHG, prob, pch = 18)
```

```{r fig=T}
barplot(freq_table)
```

$P(X=x) = e^{-\lambda}\frac{\lambda^x}{x!}$. Hence $\log P[X=x] = -\lambda + x\cdot \log \lambda - \log x!$.

```{r}
log_likelihood_poisson = function(lambda, data){
    n = length(data) # number of samples
    loglike = sum(dpois(x = data, lambda = lambda, log = T))
    return(loglike)
}
log_likelihood_poisson(lambda = 2, data = FTHG)
```

```{r fig=T}
ll = c()
for(l in lambda_star){
    ll = append(ll, log_likelihood_poisson(lambda = l, data = FTHG))
}
plot(lambda_star, ll)
best_value = lambda_star[which.max(ll)]
best_value
```

### Optimising this code

For optimising one variable `optimise`; 
for optimising many variables `optim`

```{r}
optimise(log_likelihood_poisson, c(0,10), maximum = T, data = FTHG)
```


## Fitting some complicated model

```{r}
?faithful
head(faithful)
```
```{r}
faithful %>% 
    ggplot(aes(x = eruptions, y = waiting)) +
    geom_point()

faithful %>% 
    ggplot(aes(x = waiting)) +
    geom_histogram(colour = I("white"), bins = 15)
```
Note that this data is bimodal. We can express this as linear combination of two normal distributions. Say,  
$N(52,6)$ and $N(80,8)$  
Suppose we take $p = \frac{1}{2}$. Then $p\cdot N(52,6) + (1-p)\cdot N(80,8)$ is a valid prb dist.

```{r}
waiting = sort(faithful$waiting)
hist(waiting, probability = T)
# p = 0.5
# d = p*dnorm(waiting, mean = 52, sd = 6) + (1-p)*dnorm(waiting, mean = 80, sd = 8)
# lines(waiting, d, lwd = 2)
p_hat = length(waiting[waiting<65])/length(waiting) + 0.02
d = p_hat*dnorm(waiting, mean = 52, sd = 5.5) + (1-p_hat)*dnorm(waiting, mean = 80, sd = 6.5)
lines(waiting, d, lwd = 2, fill = "red")
```

This is known as mixture model, where we take two probability distributions and make a new one.

### MLE of bimodal mixture:

```{r}
NegLokLikeMix <- function(theta, data){
    mu1 = theta[1]
    sigma1 = exp(theta[2]) # because optim runs it on the real line, but sigma needs to be positive
    
    mu2 = theta[3]
    sigma2 = exp(theta[4])
    
    p = exp(theta[5])/(1+exp(theta[5])) # logit transformation
    
    n = length(data)
    
    l = 0
    for(i in 1:n){
        l = l + log(p*dnorm(data[i], mean = mu1, sd = sigma1) + (1-p)*dnorm(data[i], mean = mu2, sd = sigma2))
    }
    return(-l)
    
}
theta_initial = c(52,8,80,8,0.5)
optim(theta_initial, 
      NegLokLikeMix, 
      data=waiting,
      control = list(maxit = 1500))
```

```{r}
theta = c(53, 5.5, 80, 6.5, 0.5)
optim(theta_initial, 
      NegLokLikeMix, 
      data=waiting,
      control = list(maxit = 1500))
```

Say we want $P[70< waiting < 100] = \int_{70}^{100} f(x) dx$.
```{r}
dMix = function(x, theta){
    mu1 = theta[1]
    sigma1 = theta[2]
    mu2 = theta[3]
    sigma2 = theta[4]
    p = theta[5]
    f = p*dnorm(x, mean = mu1, sd = sigma1) + (1-p)*dnorm(x, mean = mu2, sd = sigma2)
    return(f)
}
dMix(80, theta = theta_initial)
```
```{r}
integrate(dMix, lower = 70, upper = 100, theta_initial)
```

