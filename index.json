[{"content":"Synopsis In this project, I aim to classify 1 second long audio clips of the words \u0026ldquo;one\u0026rdquo;, \u0026ldquo;two\u0026rdquo;, \u0026ldquo;three\u0026rdquo;, \u0026hellip;, \u0026ldquo;zero\u0026rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.\nI trained 3 models on the data:\nA baseline CNN model ==========================================================================================\rLayer (type:depth-idx) Output Shape Param # ==========================================================================================\rBaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ==========================================================================================\rTotal params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3.90 ==========================================================================================\rInput size (MB): 2.88 Forward/backward pass size (MB): 207.40 Params size (MB): 0.57 Estimated Total Size (MB): 210.86 ========================================================================================== A CRNN Model, with a LSTM following a CNNBLock ==========================================================================================\rLayer (type:depth-idx) Output Shape Param #\r==========================================================================================\rCRNN [128, 10] --\r├─convbloc: 1-1 [128, 128, 22] --\r│ └─Sequential: 2-1 [128, 128, 22] --\r│ │ └─Conv1d: 3-1 [128, 128, 44] 82,048\r│ │ └─BatchNorm1d: 3-2 [128, 128, 44] 256\r│ │ └─ReLU: 3-3 [128, 128, 44] --\r│ │ └─MaxPool1d: 3-4 [128, 128, 22] --\r├─convbloc: 1-2 [128, 128, 11] --\r│ └─Sequential: 2-2 [128, 128, 11] --\r│ │ └─Conv1d: 3-5 [128, 128, 22] 82,048\r│ │ └─BatchNorm1d: 3-6 [128, 128, 22] 256\r│ │ └─ReLU: 3-7 [128, 128, 22] --\r│ │ └─MaxPool1d: 3-8 [128, 128, 11] --\r├─convbloc: 1-3 [128, 256, 5] --\r│ └─Sequential: 2-3 [128, 256, 5] --\r│ │ └─Conv1d: 3-9 [128, 256, 11] 164,096\r│ │ └─BatchNorm1d: 3-10 [128, 256, 11] 512\r│ │ └─ReLU: 3-11 [128, 256, 11] --\r│ │ └─MaxPool1d: 3-12 [128, 256, 5] --\r├─LSTM: 1-4 [128, 256, 96] 39,552\r├─Flatten: 1-5 [128, 24576] --\r├─Sequential: 1-6 [128, 64] --\r│ └─Linear: 2-4 [128, 64] 1,572,928\r│ └─ReLU: 2-5 [128, 64] --\r├─Linear: 1-7 [128, 10] 650\r├─Softmax: 1-8 [128, 10] --\r==========================================================================================\rTotal params: 1,942,346\rTrainable params: 1,942,346\rNon-trainable params: 0\rTotal mult-adds (G): 2.42\r==========================================================================================\rInput size (MB): 2.88\rForward/backward pass size (MB): 48.31\rParams size (MB): 7.77\rEstimated Total Size (MB): 58.96\r========================================================================================== A Parallel CNN-LSTM model, where we have the inputs go through 5 CNN blocks and a LSTM block parallely and then they are concatenated ==========================================================================================\rLayer (type:depth-idx) Output Shape Param #\r==========================================================================================\rParallelNet [128, 10] --\r├─CNNBLock: 1-1 [128, 16, 63, 22] --\r│ └─Sequential: 2-1 [128, 16, 63, 22] --\r│ │ └─Conv2d: 3-1 [128, 16, 126, 44] 64\r│ │ └─BatchNorm2d: 3-2 [128, 16, 126, 44] 32\r│ │ └─ReLU: 3-3 [128, 16, 126, 44] --\r│ │ └─MaxPool2d: 3-4 [128, 16, 63, 22] --\r├─CNNBLock: 1-2 [128, 32, 30, 11] --\r│ └─Sequential: 2-2 [128, 32, 30, 11] --\r│ │ └─Conv2d: 3-5 [128, 32, 61, 22] 1,568\r│ │ └─BatchNorm2d: 3-6 [128, 32, 61, 22] 64\r│ │ └─ReLU: 3-7 [128, 32, 61, 22] --\r│ │ └─MaxPool2d: 3-8 [128, 32, 30, 11] --\r├─CNNBLock: 1-3 [128, 64, 14, 5] --\r│ └─Sequential: 2-3 [128, 64, 14, 5] --\r│ │ └─Conv2d: 3-9 [128, 64, 28, 11] 6,208\r│ │ └─BatchNorm2d: 3-10 [128, 64, 28, 11] 128\r│ │ └─ReLU: 3-11 [128, 64, 28, 11] --\r│ │ └─MaxPool2d: 3-12 [128, 64, 14, 5] --\r├─CNNBLock: 1-4 [128, 64, 3, 1] --\r│ └─Sequential: 2-4 [128, 64, 3, 1] --\r│ │ └─Conv2d: 3-13 [128, 64, 12, 5] 12,352\r│ │ └─BatchNorm2d: 3-14 [128, 64, 12, 5] 128\r│ │ └─ReLU: 3-15 [128, 64, 12, 5] --\r│ │ └─MaxPool2d: 3-16 [128, 64, 3, 1] --\r├─Flatten: 1-5 [128, 192] --\r├─RNNBlock: 1-6 [128, 32, 256] --\r│ └─MaxPool2d: 2-5 [128, 1, 32, 22] --\r│ └─LSTM: 2-6 [128, 32, 256] 155,648\r├─Flatten: 1-7 [128, 8192] --\r├─Linear: 1-8 [128, 10] 83,850\r├─Softmax: 1-9 [128, 10] --\r==========================================================================================\rTotal params: 260,042\rTrainable params: 260,042\rNon-trainable params: 0\rTotal mult-adds (G): 1.30\r==========================================================================================\rInput size (MB): 2.88\rForward/backward pass size (MB): 326.25\rParams size (MB): 1.04\rEstimated Total Size (MB): 330.17\r========================================================================================== Model performance Model performance on the validation and test sets for each of the model and the number of epochs they were trained for is listed in the table below.\nModel\r# epochs\rValidation accuracy\rTest accuracy\rBaseline\r3\u0026nbsp;\r\u0026nbsp;26.4\r27.6\u0026nbsp;\r\u0026nbsp;CRNN\r3\u0026nbsp;\r\u0026nbsp;56.94\r56.62\u0026nbsp;\r\u0026nbsp;Parallel CNN-LSTM\r6\u0026nbsp;\r84.92\u0026nbsp;\r\u0026nbsp;84.29\rClassification report for Parallel CNN-LSTM:\nPrecision Recall F1-score Support zero 0.91 0.87 0.89 250 one 0.71 0.9 0.79 248 two 0.78 0.81 0.8 264 three 0.81 0.91 0.86 267 four 0.91 0.76 0.83 253 five 0.86 0.73 0.79 271 six 0.95 0.89 0.92 244 seven 0.81 0.92 0.85 239 eight 0.91 0.82 0.86 257 nine 0.84 0.83 0.83 259 Accuracy 0.84 2552 Macro avg 0.85 0.84 0.84 2552 Weighted avg 0.85 0.84 0.84 2552 Final training was done for small number of epochs because of lack of gpu due to a gpu error, and also decreasing validation accuracy if trained after that point.\nLinks GitHub: word-classification-with-pytorch\nReport: Link\n","permalink":"https://roudranil.github.io/projects/audio-classification/","summary":"Synopsis In this project, I aim to classify 1 second long audio clips of the words \u0026ldquo;one\u0026rdquo;, \u0026ldquo;two\u0026rdquo;, \u0026ldquo;three\u0026rdquo;, \u0026hellip;, \u0026ldquo;zero\u0026rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.\nI trained 3 models on the data:\nA baseline CNN model ==========================================================================================\rLayer (type:depth-idx) Output Shape Param # ==========================================================================================\rBaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ==========================================================================================\rTotal params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3.","title":"Audio Classification with CNN-LSTM networks"},{"content":"Synopsis In this project we explore the trends of deforestation in the past 3 decades. We use visualisation techniques in order to find patterns behind deforestation and it\u0026rsquo;s driving factors. Following this, we attempt to answer questions regarding conversion of forests to land for other purposes and questions regarding Brazil\u0026rsquo;s excessive loss of forest cover. Then we aim to develop a dashboard to explore the above posed questions.\nLinks GitHub: deforestation-and-forest-conversion\nReport: link\nR Shiny dashboard: link\n","permalink":"https://roudranil.github.io/projects/visualisation/","summary":"Synopsis In this project we explore the trends of deforestation in the past 3 decades. We use visualisation techniques in order to find patterns behind deforestation and it\u0026rsquo;s driving factors. Following this, we attempt to answer questions regarding conversion of forests to land for other purposes and questions regarding Brazil\u0026rsquo;s excessive loss of forest cover. Then we aim to develop a dashboard to explore the above posed questions.\nLinks GitHub: deforestation-and-forest-conversion","title":"Forests and Deforestation"},{"content":" Semester 1 (Aug - Nov 2022) Programming and Data Structures in Python 4 credits course.\nIntroduction to Python Programming Object Oriented programming\nThere\u0026rsquo;s a section on linked lists and flexible lists in it as well. Algorithms and Data Structures Associated Jupyter Notebook For NumPy and Pandas I would recommend the following resources:\nIntroduction to NumPy Data Manipulation with Pandas Probability and Statistics with R 4 credits course.\nClass notes for probability and statistics R programming classwork (Contains code for some things shown in the class notes.)\na. Football betting data analysis Mathematical Methods - Analysis 4 credits course.\nAlthough there is no class notes that I can upload, a good idea is to follow Principles of Mathematical Analysis by Walter Rudin and Introduction to Real Analysis by Bartle and Sherbert.\nFor Riemann Integration, a good resource to brush up quickly on the topic is here.\nFor multivariable calculus, it\u0026rsquo;s usually recommended to follow Calculus, Volume 2 by Tom M. Apostol. Personally I do find Multivariable Calculus by Don Shimamoto to be very useful as well.\nVisualisation with R 2 credits course.\nAssociated R markdown file RDBMS and SQL 2 credits course.\nIntroduction to RDBMS and SQL ","permalink":"https://roudranil.github.io/academics/notes/","summary":"Semester 1 (Aug - Nov 2022) Programming and Data Structures in Python 4 credits course.\nIntroduction to Python Programming Object Oriented programming\nThere\u0026rsquo;s a section on linked lists and flexible lists in it as well. Algorithms and Data Structures Associated Jupyter Notebook For NumPy and Pandas I would recommend the following resources:\nIntroduction to NumPy Data Manipulation with Pandas Probability and Statistics with R 4 credits course.\nClass notes for probability and statistics R programming classwork (Contains code for some things shown in the class notes.","title":"Notes for MSc. Data Science at CMI"},{"content":"Synopsis We conduct a survey where we test the respondent\u0026rsquo;s knowledge on 4 aspenct: financial knowledge and skills, financial attitude and knowledge about inflation and other parameters. Using these we attempt to judge their financial literacy.\nThis project is being conducted by by 5 first year MSc. Data Science students at the Chennai Mathematical Institute: Me, Adarsha Mondal, Shreyan Chakraborty, Deepmalya Dutta and Ujan Dasgputa.\nThe project is in progress. More information will be added at a later point of time.\n","permalink":"https://roudranil.github.io/projects/financial-literacy/","summary":"Synopsis We conduct a survey where we test the respondent\u0026rsquo;s knowledge on 4 aspenct: financial knowledge and skills, financial attitude and knowledge about inflation and other parameters. Using these we attempt to judge their financial literacy.\nThis project is being conducted by by 5 first year MSc. Data Science students at the Chennai Mathematical Institute: Me, Adarsha Mondal, Shreyan Chakraborty, Deepmalya Dutta and Ujan Dasgputa.\nThe project is in progress. More information will be added at a later point of time.","title":"Financial Literacy among 18-35 year olds"},{"content":"Synopsis 2020 saw the onset of the onset of the Covid-19 pandemic cause by the SARS-CoV-2 virus. With the number of daily affected people and number of deaths due to the pandemic climbing sharply, a vaccine was the need of the hour. In this paper we consider one such vaccine, the ChAdOx1 nCoV-19 (AZD1222) vaccine (known as Covishield in India), and we investigate its efficacy based on studies of four randomised controlled trials held in Brazil, South Africa, and the United Kingdom. We use the Bayesian paradigm to model the posterior distribution of the vaccine efficacy and calculate its credible interval.\nMethods: In order to perform Bayesian inference, we impose prior distributions on the incidence rate of infection in the vaccine and the control cohorts. In another model we impose prior distributions of the parameters of the infection process in both cohorts. The likelihood of observed data is then chosen suitably, and the data is collected from “Safety and efficacy of the ChAdOx1 nCoV-19 vaccine (AZD1222) against SARS-CoV-2: an interim analysis of four randomised controlled trials in Brazil, South Africa, and the UK”, by Voysey et al. Vaccine efficacy is then modelled as a function of these parameters (i.e., either the incidence rates or parameters of infection processes). Using Bayes’ Theorem, we then compute the posterior densities of the parameters and vaccine efficacy consequently.\nResults: Using the posterior density of vaccine efficacy we can compute the predicted vaccine efficacy, and also the corresponding 95% Bayesian Credible Intervals. The values obtained by Bayesian methods are in excellent agreement with those obtained in the paper.\nConcluding remarks: From the results of our models, we can conclude that a Bayesian analysis of vaccine clinical trials data is also a viable method to compute the efficacy.\nLinks The full text of the project paper is available here.\nThe code associated with the paper (as well as the paper itself) can be found in this repo.\n","permalink":"https://roudranil.github.io/projects/dissertation/","summary":"Synopsis 2020 saw the onset of the onset of the Covid-19 pandemic cause by the SARS-CoV-2 virus. With the number of daily affected people and number of deaths due to the pandemic climbing sharply, a vaccine was the need of the hour. In this paper we consider one such vaccine, the ChAdOx1 nCoV-19 (AZD1222) vaccine (known as Covishield in India), and we investigate its efficacy based on studies of four randomised controlled trials held in Brazil, South Africa, and the United Kingdom.","title":"Bayesian Analysis of Efficacy of the ChAd0x1 nCoV-19 (AZD1222) Vaccine"},{"content":"Introduction I am Roudranil Das, a first year MSc. Data Science student at the Chennai Mathematical Institute, India and I did my bachelors in Mathematics from St. Xavier\u0026rsquo;s College, Kolkata.\nI am interested in the applications of AI/ML in the financial sector. Lately I have taken a keen interest in audio signal processing for Machine Learning and application of DL models for audio detection and other use cases.\nBesides, I am also a musician! I have been playing the mandolin for the past 5 years. Alongside the mandolin, I also play the banjo and melodica.\nCourses taken Following are the courses i have taken in my undergraduate and postgraduate degrees.\nUndergraduate * Real Analysis: Single and multi variable calculus\r* Differential Equations: ODE, PDE, Dynamical systems\r* Linear Algebra\r* Abstract Algebra: Groups, Rings, Fields\r* Numerical Methods\r* Linear Programming and Convex Optimisation\r* Mathematical Statistcs\r* C and R programming\r* Complex Analysis\r* Metric Spaces\rPostgraduate * Programming and Data Structures in Python\r* Probability and Statistics with R\r* Visualisation in R\r* Real Analysis: Single and multi variable calculus\r* RDBMS and SQL\rAwards and Achievements 2017 : Jagadish Bose National Science Talent Search Junior Scholarship Awardee\nQualified to be one of the 140 junior scholars of the prestigious JBNSTS scholarship program, chosen among roughly 15,000 candidates across West Bengal and selected after 2 rounds of written test and interview. 2019 : Jagadish Bose National Science Talent Search Senior Scholarship Awardee\nQualified to be one of the 60 senior scholars of the prestigious JBNSTS senior scholarship program, chosen among roughly 10,000 candidates across West Bengal and selected after 3 rounds of written test, interviews and scientific creativity test. 2019 : DST-INSPIRE Scholarship for Higher Education, Department of Science and Technology, Government of India\nQualified to be a scholar under the DST-INSPIRE Scholarship of Higher Education scheme by virtue of being a JBNSTS senior scholar and also by being in the top 1% in the country based on ISC marks. Skills $\\text{\\LaTeX}$\nResume Resume\n","permalink":"https://roudranil.github.io/about/","summary":"Introduction I am Roudranil Das, a first year MSc. Data Science student at the Chennai Mathematical Institute, India and I did my bachelors in Mathematics from St. Xavier\u0026rsquo;s College, Kolkata.\nI am interested in the applications of AI/ML in the financial sector. Lately I have taken a keen interest in audio signal processing for Machine Learning and application of DL models for audio detection and other use cases.\nBesides, I am also a musician!","title":"About me"},{"content":"You can reach out to me via mail at roudranil@cmi.ac.in.\nYou can also hit me up on Discord at Rudy#3402.\nFeel free to connect with me on LinkedIn.\n","permalink":"https://roudranil.github.io/contact/","summary":"You can reach out to me via mail at roudranil@cmi.ac.in.\nYou can also hit me up on Discord at Rudy#3402.\nFeel free to connect with me on LinkedIn.","title":"Contact"}]