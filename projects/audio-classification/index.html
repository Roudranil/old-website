<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Audio Classification with CNN-LSTM networks | Roudranil</title><meta name=keywords content><meta name=description content="Synopsis In this project, I aim to classify 1 second long audio clips of the words &ldquo;one&rdquo;, &ldquo;two&rdquo;, &ldquo;three&rdquo;, &mldr;, &ldquo;zero&rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.
I trained 3 models on the data:
A baseline CNN model ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== BaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ========================================================================================== Total params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3."><meta name=author content="Roudranil"><link rel=canonical href=https://roudranil.github.io/projects/audio-classification/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://roudranil.github.io/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://roudranil.github.io/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://roudranil.github.io/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://roudranil.github.io/favicon/apple_touch_icon.png><link rel=mask-icon href=https://roudranil.github.io/favicon/safari_pinned_tab.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><meta property="og:title" content="Audio Classification with CNN-LSTM networks"><meta property="og:description" content="Synopsis In this project, I aim to classify 1 second long audio clips of the words &ldquo;one&rdquo;, &ldquo;two&rdquo;, &ldquo;three&rdquo;, &mldr;, &ldquo;zero&rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.
I trained 3 models on the data:
A baseline CNN model ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== BaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ========================================================================================== Total params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3."><meta property="og:type" content="article"><meta property="og:url" content="https://roudranil.github.io/projects/audio-classification/"><meta property="article:section" content="projects"><meta property="article:published_time" content="2023-01-01T09:00:37+05:30"><meta property="article:modified_time" content="2023-01-01T12:18:16+05:30"><meta property="og:site_name" content="Roudranil"><meta name=twitter:card content="summary"><meta name=twitter:title content="Audio Classification with CNN-LSTM networks"><meta name=twitter:description content="Synopsis In this project, I aim to classify 1 second long audio clips of the words &ldquo;one&rdquo;, &ldquo;two&rdquo;, &ldquo;three&rdquo;, &mldr;, &ldquo;zero&rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.
I trained 3 models on the data:
A baseline CNN model ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== BaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ========================================================================================== Total params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://roudranil.github.io/projects/"},{"@type":"ListItem","position":2,"name":"Audio Classification with CNN-LSTM networks","item":"https://roudranil.github.io/projects/audio-classification/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Audio Classification with CNN-LSTM networks","name":"Audio Classification with CNN-LSTM networks","description":"Synopsis In this project, I aim to classify 1 second long audio clips of the words \u0026ldquo;one\u0026rdquo;, \u0026ldquo;two\u0026rdquo;, \u0026ldquo;three\u0026rdquo;, \u0026hellip;, \u0026ldquo;zero\u0026rdquo;. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.\nI trained 3 models on the data:\nA baseline CNN model ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== BaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ========================================================================================== Total params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3.","keywords":[],"articleBody":"Synopsis In this project, I aim to classify 1 second long audio clips of the words “one”, “two”, “three”, …, “zero”. The data for this project is taken from the TensorFlow Speech Recognition Challenge. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.\nI trained 3 models on the data:\nA baseline CNN model ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== BaseModel [128, 10] -- ├─convblock: 1-1 [128, 16, 65, 23] -- │ └─Sequential: 2-1 [128, 16, 65, 23] -- │ │ └─Conv2d: 3-1 [128, 16, 130, 46] 160 │ │ └─ReLU: 3-2 [128, 16, 130, 46] -- │ │ └─MaxPool2d: 3-3 [128, 16, 65, 23] -- ├─convblock: 1-2 [128, 32, 33, 12] -- │ └─Sequential: 2-2 [128, 32, 33, 12] -- │ │ └─Conv2d: 3-4 [128, 32, 67, 25] 4,640 │ │ └─ReLU: 3-5 [128, 32, 67, 25] -- │ │ └─MaxPool2d: 3-6 [128, 32, 33, 12] -- ├─convblock: 1-3 [128, 64, 17, 7] -- │ └─Sequential: 2-3 [128, 64, 17, 7] -- │ │ └─Conv2d: 3-7 [128, 64, 35, 14] 18,496 │ │ └─ReLU: 3-8 [128, 64, 35, 14] -- │ │ └─MaxPool2d: 3-9 [128, 64, 17, 7] -- ├─convblock: 1-4 [128, 128, 9, 4] -- │ └─Sequential: 2-4 [128, 128, 9, 4] -- │ │ └─Conv2d: 3-10 [128, 128, 19, 9] 73,856 │ │ └─ReLU: 3-11 [128, 128, 19, 9] -- │ │ └─MaxPool2d: 3-12 [128, 128, 9, 4] -- ├─Flatten: 1-5 [128, 4608] -- ├─Linear: 1-6 [128, 10] 46,090 ├─Softmax: 1-7 [128, 10] -- ========================================================================================== Total params: 143,242 Trainable params: 143,242 Non-trainable params: 0 Total mult-adds (G): 3.90 ========================================================================================== Input size (MB): 2.88 Forward/backward pass size (MB): 207.40 Params size (MB): 0.57 Estimated Total Size (MB): 210.86 ========================================================================================== A CRNN Model, with a LSTM following a CNNBLock ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== CRNN [128, 10] -- ├─convbloc: 1-1 [128, 128, 22] -- │ └─Sequential: 2-1 [128, 128, 22] -- │ │ └─Conv1d: 3-1 [128, 128, 44] 82,048 │ │ └─BatchNorm1d: 3-2 [128, 128, 44] 256 │ │ └─ReLU: 3-3 [128, 128, 44] -- │ │ └─MaxPool1d: 3-4 [128, 128, 22] -- ├─convbloc: 1-2 [128, 128, 11] -- │ └─Sequential: 2-2 [128, 128, 11] -- │ │ └─Conv1d: 3-5 [128, 128, 22] 82,048 │ │ └─BatchNorm1d: 3-6 [128, 128, 22] 256 │ │ └─ReLU: 3-7 [128, 128, 22] -- │ │ └─MaxPool1d: 3-8 [128, 128, 11] -- ├─convbloc: 1-3 [128, 256, 5] -- │ └─Sequential: 2-3 [128, 256, 5] -- │ │ └─Conv1d: 3-9 [128, 256, 11] 164,096 │ │ └─BatchNorm1d: 3-10 [128, 256, 11] 512 │ │ └─ReLU: 3-11 [128, 256, 11] -- │ │ └─MaxPool1d: 3-12 [128, 256, 5] -- ├─LSTM: 1-4 [128, 256, 96] 39,552 ├─Flatten: 1-5 [128, 24576] -- ├─Sequential: 1-6 [128, 64] -- │ └─Linear: 2-4 [128, 64] 1,572,928 │ └─ReLU: 2-5 [128, 64] -- ├─Linear: 1-7 [128, 10] 650 ├─Softmax: 1-8 [128, 10] -- ========================================================================================== Total params: 1,942,346 Trainable params: 1,942,346 Non-trainable params: 0 Total mult-adds (G): 2.42 ========================================================================================== Input size (MB): 2.88 Forward/backward pass size (MB): 48.31 Params size (MB): 7.77 Estimated Total Size (MB): 58.96 ========================================================================================== A Parallel CNN-LSTM model, where we have the inputs go through 5 CNN blocks and a LSTM block parallely and then they are concatenated ========================================================================================== Layer (type:depth-idx) Output Shape Param # ========================================================================================== ParallelNet [128, 10] -- ├─CNNBLock: 1-1 [128, 16, 63, 22] -- │ └─Sequential: 2-1 [128, 16, 63, 22] -- │ │ └─Conv2d: 3-1 [128, 16, 126, 44] 64 │ │ └─BatchNorm2d: 3-2 [128, 16, 126, 44] 32 │ │ └─ReLU: 3-3 [128, 16, 126, 44] -- │ │ └─MaxPool2d: 3-4 [128, 16, 63, 22] -- ├─CNNBLock: 1-2 [128, 32, 30, 11] -- │ └─Sequential: 2-2 [128, 32, 30, 11] -- │ │ └─Conv2d: 3-5 [128, 32, 61, 22] 1,568 │ │ └─BatchNorm2d: 3-6 [128, 32, 61, 22] 64 │ │ └─ReLU: 3-7 [128, 32, 61, 22] -- │ │ └─MaxPool2d: 3-8 [128, 32, 30, 11] -- ├─CNNBLock: 1-3 [128, 64, 14, 5] -- │ └─Sequential: 2-3 [128, 64, 14, 5] -- │ │ └─Conv2d: 3-9 [128, 64, 28, 11] 6,208 │ │ └─BatchNorm2d: 3-10 [128, 64, 28, 11] 128 │ │ └─ReLU: 3-11 [128, 64, 28, 11] -- │ │ └─MaxPool2d: 3-12 [128, 64, 14, 5] -- ├─CNNBLock: 1-4 [128, 64, 3, 1] -- │ └─Sequential: 2-4 [128, 64, 3, 1] -- │ │ └─Conv2d: 3-13 [128, 64, 12, 5] 12,352 │ │ └─BatchNorm2d: 3-14 [128, 64, 12, 5] 128 │ │ └─ReLU: 3-15 [128, 64, 12, 5] -- │ │ └─MaxPool2d: 3-16 [128, 64, 3, 1] -- ├─Flatten: 1-5 [128, 192] -- ├─RNNBlock: 1-6 [128, 32, 256] -- │ └─MaxPool2d: 2-5 [128, 1, 32, 22] -- │ └─LSTM: 2-6 [128, 32, 256] 155,648 ├─Flatten: 1-7 [128, 8192] -- ├─Linear: 1-8 [128, 10] 83,850 ├─Softmax: 1-9 [128, 10] -- ========================================================================================== Total params: 260,042 Trainable params: 260,042 Non-trainable params: 0 Total mult-adds (G): 1.30 ========================================================================================== Input size (MB): 2.88 Forward/backward pass size (MB): 326.25 Params size (MB): 1.04 Estimated Total Size (MB): 330.17 ========================================================================================== Model performance Model performance on the validation and test sets for each of the model and the number of epochs they were trained for is listed in the table below.\nModel Num epochs Validation acc Test acc Baseline 3 26.4 27.6 CRNN 3 56.94 56.62 Parallel CNN-LSTM 6 84.92 84.29 Classification report for Parallel CNN-LSTM:\nprecision recall f1-score support zero 0.91 0.87 0.89 250 one 0.71 0.9 0.79 248 two 0.78 0.81 0.8 264 three 0.81 0.91 0.86 267 four 0.91 0.76 0.83 253 five 0.86 0.73 0.79 271 six 0.95 0.89 0.92 244 seven 0.81 0.92 0.85 239 eight 0.91 0.82 0.86 257 nine 0.84 0.83 0.83 259 accuracy 0.84 2552 macro avg 0.85 0.84 0.84 2552 weighted avg 0.85 0.84 0.84 2552 Final training was done for small number of epochs because of lack of gpu due to a gpu error, and also decreasing validation accuracy if trained after that point.\nLinks GitHub: word-classification-with-pytorch\nReport: Link\n","wordCount":"1002","inLanguage":"en","datePublished":"2023-01-01T09:00:37+05:30","dateModified":"2023-01-01T12:18:16+05:30","author":{"@type":"Person","name":"Roudranil"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://roudranil.github.io/projects/audio-classification/"},"publisher":{"@type":"Organization","name":"Roudranil","logo":{"@type":"ImageObject","url":"https://roudranil.github.io/favicon/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://roudranil.github.io/ accesskey=h title="Roudranil (Alt + H)">Roudranil</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://roudranil.github.io/about/ title=About><span>About</span></a></li><li><a href=https://roudranil.github.io/projects title=Projects><span>Projects</span></a></li><li><a href=https://roudranil.github.io/academics title=Academics><span>Academics</span></a></li><li><a href=https://roudranil.github.io/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://roudranil.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://roudranil.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://roudranil.github.io/projects/>Projects</a></div><h1 class=post-title>Audio Classification with CNN-LSTM networks</h1><div class=post-meta><span title='2023-01-01 09:00:37 +0530 +0530'>January 1, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Roudranil</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#synopsis>Synopsis</a></li><li><a href=#model-performance>Model performance</a></li><li><a href=#links>Links</a></li></ul></nav></div></details></div><div style=text-align:left class=post-content><h2 id=synopsis>Synopsis<a hidden class=anchor aria-hidden=true href=#synopsis>#</a></h2><p>In this project, I aim to classify 1 second long audio clips of the words &ldquo;one&rdquo;, &ldquo;two&rdquo;, &ldquo;three&rdquo;, &mldr;, &ldquo;zero&rdquo;. The data for this project is taken from the <a href=https:%5C%5Cwww.kaggle.com%5Ccompetitions%5Ctensorflow-speech-recognition-challenge%5Coverview>TensorFlow Speech Recognition Challenge</a>. However I have slightly deviated from the competition, in terms of the target classes, where I have truncated the target classes to the ones I mentioned above.</p><p>I trained 3 models on the data:</p><ol><li>A baseline CNN model</li></ol><pre tabindex=0><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #  
==========================================================================================
BaseModel                                [128, 10]                 --  
├─convblock: 1-1                         [128, 16, 65, 23]         --  
│    └─Sequential: 2-1                   [128, 16, 65, 23]         --  
│    │    └─Conv2d: 3-1                  [128, 16, 130, 46]        160  
│    │    └─ReLU: 3-2                    [128, 16, 130, 46]        --  
│    │    └─MaxPool2d: 3-3               [128, 16, 65, 23]         --  
├─convblock: 1-2                         [128, 32, 33, 12]         --  
│    └─Sequential: 2-2                   [128, 32, 33, 12]         --  
│    │    └─Conv2d: 3-4                  [128, 32, 67, 25]         4,640  
│    │    └─ReLU: 3-5                    [128, 32, 67, 25]         --  
│    │    └─MaxPool2d: 3-6               [128, 32, 33, 12]         --  
├─convblock: 1-3                         [128, 64, 17, 7]          --  
│    └─Sequential: 2-3                   [128, 64, 17, 7]          --  
│    │    └─Conv2d: 3-7                  [128, 64, 35, 14]         18,496  
│    │    └─ReLU: 3-8                    [128, 64, 35, 14]         --  
│    │    └─MaxPool2d: 3-9               [128, 64, 17, 7]          --  
├─convblock: 1-4                         [128, 128, 9, 4]          --  
│    └─Sequential: 2-4                   [128, 128, 9, 4]          --  
│    │    └─Conv2d: 3-10                 [128, 128, 19, 9]         73,856  
│    │    └─ReLU: 3-11                   [128, 128, 19, 9]         --  
│    │    └─MaxPool2d: 3-12              [128, 128, 9, 4]          --  
├─Flatten: 1-5                           [128, 4608]               --  
├─Linear: 1-6                            [128, 10]                 46,090  
├─Softmax: 1-7                           [128, 10]                 --  
==========================================================================================
Total params: 143,242  
Trainable params: 143,242  
Non-trainable params: 0  
Total mult-adds (G): 3.90  
==========================================================================================
Input size (MB): 2.88  
Forward/backward pass size (MB): 207.40  
Params size (MB): 0.57  
Estimated Total Size (MB): 210.86  
==========================================================================================
</code></pre><ol start=2><li>A CRNN Model, with a LSTM following a CNNBLock</li></ol><pre tabindex=0><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
CRNN                                     [128, 10]                 --
├─convbloc: 1-1                          [128, 128, 22]            --
│    └─Sequential: 2-1                   [128, 128, 22]            --
│    │    └─Conv1d: 3-1                  [128, 128, 44]            82,048
│    │    └─BatchNorm1d: 3-2             [128, 128, 44]            256
│    │    └─ReLU: 3-3                    [128, 128, 44]            --
│    │    └─MaxPool1d: 3-4               [128, 128, 22]            --
├─convbloc: 1-2                          [128, 128, 11]            --
│    └─Sequential: 2-2                   [128, 128, 11]            --
│    │    └─Conv1d: 3-5                  [128, 128, 22]            82,048
│    │    └─BatchNorm1d: 3-6             [128, 128, 22]            256
│    │    └─ReLU: 3-7                    [128, 128, 22]            --
│    │    └─MaxPool1d: 3-8               [128, 128, 11]            --
├─convbloc: 1-3                          [128, 256, 5]             --
│    └─Sequential: 2-3                   [128, 256, 5]             --
│    │    └─Conv1d: 3-9                  [128, 256, 11]            164,096
│    │    └─BatchNorm1d: 3-10            [128, 256, 11]            512
│    │    └─ReLU: 3-11                   [128, 256, 11]            --
│    │    └─MaxPool1d: 3-12              [128, 256, 5]             --
├─LSTM: 1-4                              [128, 256, 96]            39,552
├─Flatten: 1-5                           [128, 24576]              --
├─Sequential: 1-6                        [128, 64]                 --
│    └─Linear: 2-4                       [128, 64]                 1,572,928
│    └─ReLU: 2-5                         [128, 64]                 --
├─Linear: 1-7                            [128, 10]                 650
├─Softmax: 1-8                           [128, 10]                 --
==========================================================================================
Total params: 1,942,346
Trainable params: 1,942,346
Non-trainable params: 0
Total mult-adds (G): 2.42
==========================================================================================
Input size (MB): 2.88
Forward/backward pass size (MB): 48.31
Params size (MB): 7.77
Estimated Total Size (MB): 58.96
==========================================================================================
</code></pre><ol start=3><li>A Parallel CNN-LSTM model, where we have the inputs go through 5 CNN blocks and a LSTM block parallely and then they are concatenated</li></ol><pre tabindex=0><code>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ParallelNet                              [128, 10]                 --
├─CNNBLock: 1-1                          [128, 16, 63, 22]         --
│    └─Sequential: 2-1                   [128, 16, 63, 22]         --
│    │    └─Conv2d: 3-1                  [128, 16, 126, 44]        64
│    │    └─BatchNorm2d: 3-2             [128, 16, 126, 44]        32
│    │    └─ReLU: 3-3                    [128, 16, 126, 44]        --
│    │    └─MaxPool2d: 3-4               [128, 16, 63, 22]         --
├─CNNBLock: 1-2                          [128, 32, 30, 11]         --
│    └─Sequential: 2-2                   [128, 32, 30, 11]         --
│    │    └─Conv2d: 3-5                  [128, 32, 61, 22]         1,568
│    │    └─BatchNorm2d: 3-6             [128, 32, 61, 22]         64
│    │    └─ReLU: 3-7                    [128, 32, 61, 22]         --
│    │    └─MaxPool2d: 3-8               [128, 32, 30, 11]         --
├─CNNBLock: 1-3                          [128, 64, 14, 5]          --
│    └─Sequential: 2-3                   [128, 64, 14, 5]          --
│    │    └─Conv2d: 3-9                  [128, 64, 28, 11]         6,208
│    │    └─BatchNorm2d: 3-10            [128, 64, 28, 11]         128
│    │    └─ReLU: 3-11                   [128, 64, 28, 11]         --
│    │    └─MaxPool2d: 3-12              [128, 64, 14, 5]          --
├─CNNBLock: 1-4                          [128, 64, 3, 1]           --
│    └─Sequential: 2-4                   [128, 64, 3, 1]           --
│    │    └─Conv2d: 3-13                 [128, 64, 12, 5]          12,352
│    │    └─BatchNorm2d: 3-14            [128, 64, 12, 5]          128
│    │    └─ReLU: 3-15                   [128, 64, 12, 5]          --
│    │    └─MaxPool2d: 3-16              [128, 64, 3, 1]           --
├─Flatten: 1-5                           [128, 192]                --
├─RNNBlock: 1-6                          [128, 32, 256]            --
│    └─MaxPool2d: 2-5                    [128, 1, 32, 22]          --
│    └─LSTM: 2-6                         [128, 32, 256]            155,648
├─Flatten: 1-7                           [128, 8192]               --
├─Linear: 1-8                            [128, 10]                 83,850
├─Softmax: 1-9                           [128, 10]                 --
==========================================================================================
Total params: 260,042
Trainable params: 260,042
Non-trainable params: 0
Total mult-adds (G): 1.30
==========================================================================================
Input size (MB): 2.88
Forward/backward pass size (MB): 326.25
Params size (MB): 1.04
Estimated Total Size (MB): 330.17
==========================================================================================
</code></pre><h2 id=model-performance>Model performance<a hidden class=anchor aria-hidden=true href=#model-performance>#</a></h2><p>Model performance on the validation and test sets for each of the model and the number of epochs they were trained for is listed in the table below.</p><table><thead><tr><th>Model</th><th>Num epochs</th><th>Validation acc</th><th>Test acc</th></tr></thead><tbody><tr><td>Baseline</td><td>3</td><td>26.4</td><td>27.6</td></tr><tr><td>CRNN</td><td>3</td><td>56.94</td><td>56.62</td></tr><tr><td>Parallel CNN-LSTM</td><td>6</td><td>84.92</td><td>84.29</td></tr></tbody></table><p>Classification report for Parallel CNN-LSTM:</p><table><thead><tr><th></th><th>precision</th><th>recall</th><th>f1-score</th><th>support</th></tr></thead><tbody><tr><td>zero</td><td>0.91</td><td>0.87</td><td>0.89</td><td>250</td></tr><tr><td>one</td><td>0.71</td><td>0.9</td><td>0.79</td><td>248</td></tr><tr><td>two</td><td>0.78</td><td>0.81</td><td>0.8</td><td>264</td></tr><tr><td>three</td><td>0.81</td><td>0.91</td><td>0.86</td><td>267</td></tr><tr><td>four</td><td>0.91</td><td>0.76</td><td>0.83</td><td>253</td></tr><tr><td>five</td><td>0.86</td><td>0.73</td><td>0.79</td><td>271</td></tr><tr><td>six</td><td>0.95</td><td>0.89</td><td>0.92</td><td>244</td></tr><tr><td>seven</td><td>0.81</td><td>0.92</td><td>0.85</td><td>239</td></tr><tr><td>eight</td><td>0.91</td><td>0.82</td><td>0.86</td><td>257</td></tr><tr><td>nine</td><td>0.84</td><td>0.83</td><td>0.83</td><td>259</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>accuracy</td><td></td><td></td><td>0.84</td><td>2552</td></tr><tr><td>macro avg</td><td>0.85</td><td>0.84</td><td>0.84</td><td>2552</td></tr><tr><td>weighted avg</td><td>0.85</td><td>0.84</td><td>0.84</td><td>2552</td></tr></tbody></table><p>Final training was done for small number of epochs because of lack of gpu due to a gpu error, and also decreasing validation accuracy if trained after that point.</p><h2 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>#</a></h2><p>GitHub: <a href=https://github.com/Roudranil/word-classification-with-pytorch>word-classification-with-pytorch</a><br>Report: <a href=https://github.com/Roudranil/word-classification-with-pytorch/blob/main/doc/report.pdf>Link</a></p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>© 2022 Roudranil Das |</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>